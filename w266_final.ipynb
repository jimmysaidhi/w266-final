{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7BzBd-N9mS1"
   },
   "source": [
    "# Final Project: Benchmarking Transformer Based Models for LGBT Hate Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so-yur1S9mS4"
   },
   "source": [
    "## 0. Setup\n",
    "\n",
    "### 0.1. Libraries and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uQnMctL9mS5",
    "outputId": "d6c77376-0580-4011-c929-df78c51501f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q torchinfo\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "!pip install emoji==0.6.0\n",
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFkfYJebSR1T",
    "outputId": "06c40d23-5077-4280-9041-3c43f9fe1f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8b9aykE9mS8",
    "outputId": "6a4e4d91-8abe-4416-ed9f-8264e8ce85f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#@title 1. Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from torchinfo import summary\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIL1eUtV9mTC"
   },
   "source": [
    "### 2. Data Setup\n",
    "\n",
    "\n",
    "We *use* the HuggingFace HateXPlain dataset: https://huggingface.co/datasets/Hate-speech-CNERG/hatexplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQkDooNsZSzg"
   },
   "outputs": [],
   "source": [
    "# Load the HateXplain dataset\n",
    "data= load_dataset(\"Hate-speech-CNERG/hatexplain\", trust_remote_code=True)\n",
    "\n",
    "# Access the train, validation, and test splits\n",
    "train_dataset = data['train']\n",
    "validation_dataset = data['validation']\n",
    "test_dataset = data['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWa-WH_gSW3p"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHfETWQ22-pi"
   },
   "outputs": [],
   "source": [
    "def add_majority_speech_col(data):\n",
    "  majority_labels = []\n",
    "  for annotator_set in data['annotators']:\n",
    "      labels = annotator_set['label']\n",
    "      majority = Counter(labels).most_common(1)[0][0]\n",
    "      majority_labels.append(majority)\n",
    "\n",
    "  data = data.add_column(f\"majority_speech\", majority_labels)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANfkyVUz8GUS"
   },
   "outputs": [],
   "source": [
    "def add_majority_target_col(data):\n",
    "    majority_targets = []\n",
    "    target_set = []\n",
    "    # Loop over each row (example) in the dataset\n",
    "    for annotator_set in data['annotators']:\n",
    "        target_set = []\n",
    "        for annotator in annotator_set['target']:\n",
    "          for target in annotator:\n",
    "            target_set.append(target)\n",
    "        majority = Counter(target_set).most_common(1)[0][0]\n",
    "        majority_targets.append(majority)\n",
    "\n",
    "    # Add the column once, after collecting all values\n",
    "    return data.add_column(\"majority_target\", majority_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKt6Gi5eSwC6"
   },
   "outputs": [],
   "source": [
    "def add_sentence_col(data):\n",
    "    sentence_set = []\n",
    "\n",
    "    # Loop over each row (example) in the dataset\n",
    "    for example in data:\n",
    "        sentence = \" \".join(example['post_tokens'])  # Join tokens into a sentence\n",
    "        sentence_set.append(sentence)\n",
    "\n",
    "    # Add the new column\n",
    "    return data.add_column(\"sentence\", sentence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIxRod6Y9KqD"
   },
   "outputs": [],
   "source": [
    "# Extract the majority target column\n",
    "train_dataset = add_majority_target_col(train_dataset)\n",
    "validation_dataset = add_majority_target_col(validation_dataset)\n",
    "test_dataset = add_majority_target_col(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVh0miev3R6H"
   },
   "outputs": [],
   "source": [
    "# Extract the majority labeled column in terms of speech type detected\n",
    "train_dataset = add_majority_speech_col(train_dataset)\n",
    "validation_dataset = add_majority_speech_col(validation_dataset)\n",
    "test_dataset = add_majority_speech_col(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvwFsMG-Cqic",
    "outputId": "e67da54f-3ace-4a46-d66c-7d3637e5141e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered train: 1270\n",
      "filtered test: 158\n",
      "filtered val: 162\n"
     ]
    }
   ],
   "source": [
    "filtered_train_dataset = train_dataset.filter(\n",
    "    lambda example: example['majority_target'].lower() == \"homosexual\"\n",
    ")\n",
    "\n",
    "filtered_test_dataset = test_dataset.filter(\n",
    "    lambda example: example['majority_target'].lower() == \"homosexual\"\n",
    ")\n",
    "\n",
    "filtered_val_dataset = validation_dataset.filter(\n",
    "    lambda example: example['majority_target'].lower() == \"homosexual\"\n",
    ")\n",
    "\n",
    "print(\"filtered train:\", len(filtered_train_dataset))\n",
    "print(\"filtered test:\", len(filtered_test_dataset))\n",
    "print(\"filtered val:\", len(filtered_val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3mg4ZtYEjcg"
   },
   "source": [
    "Concatenate post_tokens into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nvo1SAUnE_4o"
   },
   "outputs": [],
   "source": [
    "filtered_train_dataset = add_sentence_col(filtered_train_dataset)\n",
    "filtered_test_dataset = add_sentence_col(filtered_test_dataset)\n",
    "filtered_val_dataset = add_sentence_col(filtered_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXEkhgf0olF-",
    "outputId": "589ef9db-a61d-4752-c56a-1ff0aa2aa3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '11200659_gab', 'annotators': {'label': [2, 0, 2], 'annotator_id': [208, 202, 204], 'target': [['Other'], ['Homosexual'], ['Homosexual']]}, 'rationales': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]], 'post_tokens': ['i', 'am', 'sure', 'you', 'are', 'totally', 'the', 'alpha', 'faggot', 'at', 'the', 'standard', 'fuckparties'], 'majority_target': 'Homosexual', 'majority_speech': 2, 'sentence': 'i am sure you are totally the alpha faggot at the standard fuckparties'}\n"
     ]
    }
   ],
   "source": [
    "print(filtered_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUSdrw_aa0pi"
   },
   "source": [
    "## 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-hW-FR2YaPV"
   },
   "outputs": [],
   "source": [
    "candidate_labels = [\"normal\", \"offensive\", \"hatespeech\"]\n",
    "label_map = {0: \"normal\", 1: \"offensive\", 2: \"hatespeech\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ_w05wRfFAg"
   },
   "source": [
    "### Current State of Dataset\n",
    "- We filtered so the only target are homosexual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "5Z7zSEgqaz2q",
    "outputId": "859663dc-d9be-4306-b2da-e2b0158a0359"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these with actual mappings from your dataset\n",
    "train_labels = [label_map[example['majority_speech']] for example in filtered_train_dataset]\n",
    "val_labels = [label_map[example['majority_speech']] for example in filtered_val_dataset]\n",
    "test_labels = [label_map[example['majority_speech']] for example in filtered_test_dataset]\n",
    "\n",
    "# Count label occurrences\n",
    "train_dist = Counter(train_labels)\n",
    "val_dist = Counter(val_labels)\n",
    "test_dist = Counter(test_labels)\n",
    "\n",
    "# Human-readable label names\n",
    "x_labels = [label_map.get(i) for i in range(3)]\n",
    "\n",
    "# Prepare counts for aligned plotting\n",
    "train_counts = [train_dist.get(i, 0) for i in x_labels]\n",
    "val_counts = [val_dist.get(i, 0) for i in x_labels]\n",
    "test_counts = [test_dist.get(i, 0) for i in x_labels]\n",
    "\n",
    "\n",
    "# Plotting\n",
    "x = range(len(x_labels))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([i - width for i in x], train_counts, width=width, label='Train', color='skyblue')\n",
    "plt.bar(x, val_counts, width=width, label='Validation', color='lightgreen')\n",
    "plt.bar([i + width for i in x], test_counts, width=width, label='Test', color='salmon')\n",
    "\n",
    "plt.xticks(x, x_labels)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Label Distribution Across Dataset Splits\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE4l1UzvU1J_"
   },
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vrhCf1viTWu"
   },
   "source": [
    "### 3.1 Baseline Model: Most Frequent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zliPlwCTU1T7"
   },
   "outputs": [],
   "source": [
    "# Gets most common class/label\n",
    "train_labels = [max(set(annot['label']), key=annot['label'].count) for annot in filtered_train_dataset['annotators']]\n",
    "majority_class = Counter(train_labels).most_common(1)[0][0]\n",
    "\n",
    "test_labels = [max(set(annot['label']), key=annot['label'].count) for annot in filtered_test_dataset['annotators']]\n",
    "naive_predictions = [majority_class] * len(test_labels) # should all be 2 (hatespeech)\n",
    "\n",
    "most_freq_class_classifier_results = classification_report(test_labels, naive_predictions, target_names=candidate_labels, output_dict=True, zero_division=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yys_qygFw7oB"
   },
   "source": [
    "### 3.2 Baseline Model: RoBERTa-Base Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEk9SwM_xAAL",
    "outputId": "39a491ec-3d80-49c5-daa1-f5c634b06f97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Initialize ZeroShotClassification pipeline with RoBERTa\n",
    "roberta_base_classifier = pipeline(\"zero-shot-classification\", model=\"roberta-base\", tokenizer=\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ia83kkbXB5iW",
    "outputId": "d1f97433-c140-4f27-e9ac-54078c396d6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying:   6%|         | 10/158 [00:01<00:11, 12.44it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Classifying: 100%|| 158/158 [00:11<00:00, 14.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use RoBERTa-Base to predict labels on the test dataset\n",
    "results = []\n",
    "\n",
    "for example in tqdm(filtered_test_dataset, desc=\"Classifying\"):\n",
    "    result = roberta_base_classifier(example['sentence'], candidate_labels)\n",
    "    results.append({\n",
    "        \"text\": example['sentence'],\n",
    "        \"predicted_label\": result['labels'][0],\n",
    "        \"scores\": dict(zip(result['labels'], result['scores']))\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "---ZEXL_HKtR"
   },
   "source": [
    "#### Baseline RoBERTa Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNVs114k0w8A",
    "outputId": "0dad8f65-0676-42de-8a63-5d61d720585f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "true_labels = [label_map[example['majority_speech']] for example in filtered_test_dataset]\n",
    "predicted_labels = [res['predicted_label'] for res in results]\n",
    "zero_shot_roberta_results = classification_report(true_labels, predicted_labels, output_dict=True, target_names=candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg3EViViHVEO"
   },
   "source": [
    "## 4. Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PYtgzJBjw7n"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Weighted and overall metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Per-label detailed metrics\n",
    "    report = classification_report(labels, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "    # Flatten per-class results into one dict\n",
    "    per_class_metrics = {}\n",
    "    for label, scores in report.items():\n",
    "        if label in [\"0\", \"1\", \"2\"]:\n",
    "            per_class_metrics[f\"{label_map[int(label)]}_f1\"] = scores[\"f1-score\"]\n",
    "            per_class_metrics[f\"{label_map[int(label)]}_precision\"] = scores[\"precision\"]\n",
    "            per_class_metrics[f\"{label_map[int(label)]}_recall\"] = scores[\"recall\"]\n",
    "\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"accuracy\": acc,\n",
    "        **per_class_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlVw419DXDlY"
   },
   "outputs": [],
   "source": [
    "def get_tokenized_dataset(dataset, tokenizer):\n",
    "    tokenized = dataset.map(\n",
    "        lambda x: tokenizer(x[\"sentence\"], truncation=True, padding='max_length', max_length=160),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized = tokenized.rename_column(\"majority_speech\", \"labels\")\n",
    "    tokenized = tokenized.remove_columns([col for col in tokenized.column_names if col not in [\"input_ids\", \"attention_mask\", \"labels\"]])\n",
    "    tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lco81KinjIyh"
   },
   "source": [
    "### 4.0 RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0m2mZu8qGrc"
   },
   "source": [
    "#### Reload Best Model If Restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "Jo6TcyJ6qF9L",
    "outputId": "521df0fd-3ba6-4ec3-99e0-49cd3c6a4e78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-ba66e7ee25fc>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  best_trainer_roberta = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_roberta = AutoModelForSequenceClassification.from_pretrained('./roberta-finetuned-best')\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained('./roberta-finetuned-best')\n",
    "\n",
    "\n",
    "# Recreate a Trainer using the loaded model\n",
    "best_trainer_roberta = Trainer(\n",
    "    model=model_roberta,\n",
    "    tokenizer=tokenizer_roberta,\n",
    "    args=TrainingArguments(output_dir=\"./temp\", report_to=\"none\"),  # minimal setup for evaluation\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "tokenized_test_roberta = get_tokenized_dataset(filtered_test_dataset, tokenizer_roberta)\n",
    "roberta_results = best_trainer_roberta.evaluate(eval_dataset=tokenized_test_roberta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OobGAApsSZSA"
   },
   "source": [
    "#### RoBERTa Optuna hyperparameter serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "08c3f1dc696c4636bcde929a20b61045",
      "0763f7e6081c42ba9627a59c9e7b95af",
      "ea76b8f5506241c494342035634090bb",
      "ecc53997b3874b9485faa3a7071eab91",
      "3235a0bf2c1243e0b39e84dee6f24f52",
      "a74fd2c0128b4b8da66981b305efde25",
      "34a76fbb5d9e44dbbb9e8f18d6d0fbd5",
      "09e52d724f564ff6aeeea3fe1da94015",
      "11d6764c496b4c5d9eb6aa27177c52ed",
      "59bb708847b94b0c8e35bdd85447dfa7",
      "54a1a96aa57a4f9080b2b17559e3fa67"
     ]
    },
    "id": "q-1L0q0_TBhH",
    "outputId": "5120065e-6e23-45ab-c97c-4ad46c55bb47"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c3f1dc696c4636bcde929a20b61045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Tokenize the dataset with RoBERTa tokenizer\n",
    "tokenized_train_roberta = get_tokenized_dataset(filtered_train_dataset, tokenizer_roberta)\n",
    "tokenized_val_roberta= get_tokenized_dataset(filtered_val_dataset, tokenizer_roberta)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_roberta = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_roberta,\n",
    "    eval_dataset=tokenized_val_roberta,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6w8EMTt-SWL-",
    "outputId": "b4fdc2e2-a5be-4484-eaae-b24b7441dcb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:26:48,678] A new study created in memory with name: no-name-4825f896-a87b-4382-9f48-cf0e11357b9e\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.916709</td>\n",
       "      <td>0.479229</td>\n",
       "      <td>0.523627</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.922752</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0.511195</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.495146</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:28:33,653] Trial 0 finished with value: 0.4961827626949708 and parameters: {'learning_rate': 3.495271474858987e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.06642063764911296}. Best is trial 0 with value: 0.4961827626949708.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.894451</td>\n",
       "      <td>0.523917</td>\n",
       "      <td>0.537649</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.886841</td>\n",
       "      <td>0.541734</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.924012</td>\n",
       "      <td>0.541593</td>\n",
       "      <td>0.545557</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.586826</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:31:03,464] Trial 1 finished with value: 0.5415929100005901 and parameters: {'learning_rate': 4.87469689561394e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.013618717113142654}. Best is trial 1 with value: 0.5415929100005901.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.886026</td>\n",
       "      <td>0.476367</td>\n",
       "      <td>0.513757</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.474359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.899035</td>\n",
       "      <td>0.559042</td>\n",
       "      <td>0.581347</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:32:50,891] Trial 2 finished with value: 0.5590422548947894 and parameters: {'learning_rate': 2.2519954046293944e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.028469971662982364}. Best is trial 2 with value: 0.5590422548947894.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.534695</td>\n",
       "      <td>0.561525</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.910405</td>\n",
       "      <td>0.507282</td>\n",
       "      <td>0.530146</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:34:40,611] Trial 3 finished with value: 0.5072819505809196 and parameters: {'learning_rate': 3.738321838221434e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.09731587438957838}. Best is trial 2 with value: 0.5590422548947894.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.870642</td>\n",
       "      <td>0.555290</td>\n",
       "      <td>0.589936</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908488</td>\n",
       "      <td>0.513307</td>\n",
       "      <td>0.549685</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:36:33,134] Trial 4 finished with value: 0.5133066375584435 and parameters: {'learning_rate': 3.019079179866884e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.0024587608092044968}. Best is trial 2 with value: 0.5590422548947894.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/318 00:39 < 00:39, 3.99 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.996564</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 04:37:13,605] Trial 5 pruned. \n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/636 00:38 < 01:58, 4.04 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.895221</td>\n",
       "      <td>0.487045</td>\n",
       "      <td>0.549270</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:37:53,469] Trial 6 pruned. \n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/477 00:38 < 01:18, 4.03 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.951663</td>\n",
       "      <td>0.476522</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 04:38:33,424] Trial 7 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_run_roberta = trainer_roberta.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=8,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    hp_space=lambda trial: {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Uy8udB9WHm8"
   },
   "source": [
    "#### Train model with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "8yGing0RWAtj",
    "outputId": "ca7f2e41-59dc-45bb-fff6-d7b5173450e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>0.886026</td>\n",
       "      <td>0.476367</td>\n",
       "      <td>0.513757</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.474359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>0.899035</td>\n",
       "      <td>0.559042</td>\n",
       "      <td>0.581347</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./roberta-finetuned-best/tokenizer_config.json',\n",
       " './roberta-finetuned-best/special_tokens_map.json',\n",
       " './roberta-finetuned-best/vocab.json',\n",
       " './roberta-finetuned-best/merges.txt',\n",
       " './roberta-finetuned-best/added_tokens.json',\n",
       " './roberta-finetuned-best/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fresh training args with best hyperparams\n",
    "best_training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-finetuned-best\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    **best_run_roberta.hyperparameters  # inject the best values\n",
    ")\n",
    "\n",
    "# New trainer with best config\n",
    "best_trainer_roberta = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=best_training_args,\n",
    "    train_dataset=tokenized_train_roberta,\n",
    "    eval_dataset=tokenized_val_roberta,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_trainer_roberta.train()\n",
    "best_trainer_roberta.save_model(\"./roberta-finetuned-best\")\n",
    "tokenizer_roberta.save_pretrained(\"./roberta-finetuned-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "x0AWuptTkiP1",
    "outputId": "d86de248-3285-47ac-d781-ad91d7bedf45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_roberta = get_tokenized_dataset(filtered_test_dataset, tokenizer_roberta)\n",
    "roberta_results = best_trainer_roberta.evaluate(eval_dataset=tokenized_test_roberta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVpD6vSNR6hS"
   },
   "source": [
    "### 4.1 HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VocVK4Az1dZ6"
   },
   "source": [
    "#### Reload Best Model if Restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "DbSAnTSU1byi",
    "outputId": "e0b4eaa9-06a4-4533-dc08-3da0a4bea2e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-5e5580d8e966>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  best_trainer_hatebert = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hatebert = AutoModelForSequenceClassification.from_pretrained('./hatebert-finetuned-best')\n",
    "tokenizer_hatebert = AutoTokenizer.from_pretrained('./hatebert-finetuned-best')\n",
    "\n",
    "# Recreate a Trainer using the loaded model\n",
    "best_trainer_hatebert = Trainer(\n",
    "    model=model_hatebert,\n",
    "    tokenizer=tokenizer_hatebert,\n",
    "    args=TrainingArguments(output_dir=\"./temp\", report_to=\"none\"),  # minimal setup for evaluation\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "tokenized_test_hatebert = get_tokenized_dataset(filtered_test_dataset, tokenizer_hatebert)\n",
    "hatebert_results = best_trainer_hatebert.evaluate(eval_dataset=tokenized_test_hatebert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5jWPuQ01viz"
   },
   "source": [
    "#### HateBERT Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "780a7582bfd24b0fb62387175146d65d",
      "2560bfca50794be6b8dbbc6cb2e036ca",
      "81cc8a41698e4153ac336e7b247d083f",
      "f452a31b0f1041e9813e3e6d09268118",
      "e4082ae8e1284bd3b7138277ce350656",
      "8d1de86d5cf741f382eae824bc6bfbec",
      "7e573103b7b04131b71cbb8d15e160df",
      "efbe55556e5e4f0abd91965848cbce95",
      "e1906447910e4b8fb0b289c00cd17bef",
      "55fedf8a2c73494590b5b8901beea840",
      "658f80af72fe4e6a9f2c81768c442b66"
     ]
    },
    "id": "01g7sHGRTi1J",
    "outputId": "2bb41821-c194-4336-9e1d-4a8c44a74c63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a7582bfd24b0fb62387175146d65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the model and tokenizer\n",
    "model_name = \"GroNLP/hateBERT\"\n",
    "tokenizer_hatebert = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_train_hatebert = get_tokenized_dataset(filtered_train_dataset, tokenizer_hatebert)\n",
    "tokenized_val_hatebert= get_tokenized_dataset(filtered_val_dataset, tokenizer_hatebert)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./hatebert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_hatebert = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_hatebert,\n",
    "    eval_dataset=tokenized_val_hatebert,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwcIUAIBb0pD"
   },
   "source": [
    "#### HateBert Optuna hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RrXf-eZ0TuXd",
    "outputId": "3e779553-f070-4bed-b8d2-e53a839619a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:40:36,008] A new study created in memory with name: no-name-9b2e4505-3fcf-4ca2-ae98-4029bbc6949a\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 02:56, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.868142</td>\n",
       "      <td>0.536146</td>\n",
       "      <td>0.541135</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>0.881833</td>\n",
       "      <td>0.531310</td>\n",
       "      <td>0.538314</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>0.927786</td>\n",
       "      <td>0.564552</td>\n",
       "      <td>0.566449</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.972986</td>\n",
       "      <td>0.547903</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:43:34,604] Trial 0 finished with value: 0.547902678506967 and parameters: {'learning_rate': 2.638101640147654e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 4, 'weight_decay': 0.05566818550622757}. Best is trial 0 with value: 0.547902678506967.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>0.883039</td>\n",
       "      <td>0.536499</td>\n",
       "      <td>0.571058</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.605714</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.873103</td>\n",
       "      <td>0.528487</td>\n",
       "      <td>0.539128</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.865611</td>\n",
       "      <td>0.541170</td>\n",
       "      <td>0.551768</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:45:52,117] Trial 1 finished with value: 0.5411698159359138 and parameters: {'learning_rate': 2.1752476884593742e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.03174846543767401}. Best is trial 0 with value: 0.547902678506967.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 01:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.928200</td>\n",
       "      <td>0.876522</td>\n",
       "      <td>0.534822</td>\n",
       "      <td>0.542116</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>1.006737</td>\n",
       "      <td>0.525197</td>\n",
       "      <td>0.529012</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:47:37,130] Trial 2 finished with value: 0.5251967366977114 and parameters: {'learning_rate': 4.2823305350803846e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.03867665773957534}. Best is trial 0 with value: 0.547902678506967.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 02:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.942200</td>\n",
       "      <td>0.866061</td>\n",
       "      <td>0.540820</td>\n",
       "      <td>0.545498</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>0.512231</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>1.206441</td>\n",
       "      <td>0.536265</td>\n",
       "      <td>0.536782</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>1.318607</td>\n",
       "      <td>0.536505</td>\n",
       "      <td>0.538019</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:50:33,794] Trial 3 finished with value: 0.5365054049264576 and parameters: {'learning_rate': 4.595966575513792e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 4, 'weight_decay': 0.0921539345815214}. Best is trial 0 with value: 0.547902678506967.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 03:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.898005</td>\n",
       "      <td>0.486883</td>\n",
       "      <td>0.507841</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.626100</td>\n",
       "      <td>1.137129</td>\n",
       "      <td>0.491809</td>\n",
       "      <td>0.503159</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>1.674393</td>\n",
       "      <td>0.531576</td>\n",
       "      <td>0.532982</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>2.146912</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.519809</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 04:53:50,596] Trial 4 finished with value: 0.5175646480582249 and parameters: {'learning_rate': 4.367224972482427e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.021793513833736913}. Best is trial 0 with value: 0.547902678506967.\n"
     ]
    }
   ],
   "source": [
    "best_run_hatebert = trainer_hatebert.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=5,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    hp_space=lambda trial: {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "hN4mbQh1YsRX",
    "outputId": "b260f5cb-9bc4-4730-e22b-4290b730896a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 02:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.868142</td>\n",
       "      <td>0.536146</td>\n",
       "      <td>0.541135</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>0.881833</td>\n",
       "      <td>0.531310</td>\n",
       "      <td>0.538314</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>0.927786</td>\n",
       "      <td>0.564552</td>\n",
       "      <td>0.566449</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.972986</td>\n",
       "      <td>0.547903</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./hatebert-finetuned-best/tokenizer_config.json',\n",
       " './hatebert-finetuned-best/special_tokens_map.json',\n",
       " './hatebert-finetuned-best/vocab.txt',\n",
       " './hatebert-finetuned-best/added_tokens.json',\n",
       " './hatebert-finetuned-best/tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparams\n",
    "best_training_args = TrainingArguments(\n",
    "    output_dir=\"./hatebert-finetuned-best\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    **best_run_hatebert.hyperparameters\n",
    ")\n",
    "\n",
    "# Trainer with best found hyperparameters\n",
    "best_trainer_hatebert = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=best_training_args,\n",
    "    train_dataset=tokenized_train_hatebert,\n",
    "    eval_dataset=tokenized_val_hatebert,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_trainer_hatebert.train()\n",
    "best_trainer_hatebert.save_model(\"./hatebert-finetuned-best\")\n",
    "tokenizer_hatebert.save_pretrained(\"./hatebert-finetuned-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5Su_-PXZ1W6"
   },
   "source": [
    "#### HateBERT Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "5GK33tBXY5i9",
    "outputId": "e7073de5-ca40-4bb0-dc00-63545aee24dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_hatebert= get_tokenized_dataset(filtered_test_dataset, tokenizer_hatebert)\n",
    "hatebert_results = best_trainer_hatebert.evaluate(eval_dataset=tokenized_test_hatebert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3djHeqDi1Jo"
   },
   "source": [
    "### 4.2 BERTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YigQfhuaofST"
   },
   "outputs": [],
   "source": [
    "def get_tokenized_dataset_bertweet(dataset, tokenizer):\n",
    "    tokenized = dataset.map(\n",
    "        lambda x: tokenizer(x[\"sentence\"], truncation=True, padding='max_length', max_length=128),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized = tokenized.rename_column(\"majority_speech\", \"labels\")\n",
    "    tokenized = tokenized.remove_columns([col for col in tokenized.column_names if col not in [\"input_ids\", \"attention_mask\", \"labels\"]])\n",
    "    tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "3bf5eb75df154c0a827dd1950e75a139",
      "a0051abe3f0445638cea27506e90b9f8",
      "abd97d130742470193d0ada1d14fa2ce",
      "0ebac001fba84596ba313af5763c389e",
      "c1468460632e45ef8130b597e6a33ca5",
      "b5c4703f390a469c989c29c6770cc1cd",
      "245ca47130e44c6590cd64a0172edf7a",
      "563579234727487da7de92aa65929c30",
      "2e4428c2752c4fd28b73e139c9a8d25e",
      "02e6431fae7e4e2589733ed617f0e713",
      "f1833c1b51404470bc5e0355913ed116",
      "5bd81bfe406d4c81a6cb0a362d875f60",
      "b5a36cad3e2f4186aaacf20f76e66e80",
      "788149d3f8a0476bb787da78ed4b495b",
      "f65a0a88d7444eaa874abf2af74ebac4",
      "aeb45ff739e1495986c27a34db8e6b59",
      "45107998af914c078713f8b1bd515856",
      "62d608bc59bf4ced9c4da74f0aa9f457",
      "c67e34f01e9546a0b113353d98e8036e",
      "4c4799005d1c439eb972e555a372f9ca",
      "226072d1934c4b64a290cd518760bc99",
      "878eec78d5c542bd90f0fa3482d43c5c"
     ]
    },
    "id": "OCzHcZPyaIPS",
    "outputId": "c6ddaabe-974c-401f-d5f1-68000032cf21"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf5eb75df154c0a827dd1950e75a139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd81bfe406d4c81a6cb0a362d875f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vinai/bertweet-base\"\n",
    "\n",
    "# Load tokenizer and Bertweet model\n",
    "tokenizer_bertweet = AutoTokenizer.from_pretrained(model_name, use_fast=False)  # BERTweet tokenizer needs use_fast=False\n",
    "\n",
    "# Tokenize the dataset with Bertweet tokenizer\n",
    "tokenized_train_bertweet = get_tokenized_dataset_bertweet(filtered_train_dataset, tokenizer_bertweet)\n",
    "tokenized_val_bertweet= get_tokenized_dataset_bertweet(filtered_val_dataset, tokenizer_bertweet)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertweet-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_bertweet = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_bertweet,\n",
    "    eval_dataset=tokenized_val_bertweet,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUaXPGfgexpb"
   },
   "source": [
    "#### BERTweet Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MdkcO6bfeuhk",
    "outputId": "b73670ef-6203-4269-f393-250648fb828a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:09:52,485] A new study created in memory with name: no-name-4789bcf9-86ca-48d3-87d0-89e922e30448\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [477/477 02:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.947400</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.539947</td>\n",
       "      <td>0.579435</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>0.856763</td>\n",
       "      <td>0.555297</td>\n",
       "      <td>0.564052</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.938484</td>\n",
       "      <td>0.526848</td>\n",
       "      <td>0.537710</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:12:12,656] Trial 0 finished with value: 0.5268479880422087 and parameters: {'learning_rate': 2.6566876615873952e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.06676002740628996}. Best is trial 0 with value: 0.5268479880422087.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:22, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>0.585329</td>\n",
       "      <td>0.588749</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>0.840228</td>\n",
       "      <td>0.553386</td>\n",
       "      <td>0.565454</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:13:41,397] Trial 1 finished with value: 0.5533859440836184 and parameters: {'learning_rate': 3.275270882917601e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.06986173422963689}. Best is trial 1 with value: 0.5533859440836184.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 03:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.020500</td>\n",
       "      <td>1.035845</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.041500</td>\n",
       "      <td>1.041960</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.034500</td>\n",
       "      <td>1.031359</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.034900</td>\n",
       "      <td>1.032015</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:16:57,265] Trial 2 finished with value: 0.312962962962963 and parameters: {'learning_rate': 3.190297310378158e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.03447332741725234}. Best is trial 1 with value: 0.5533859440836184.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.906898</td>\n",
       "      <td>0.460703</td>\n",
       "      <td>0.424003</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607330</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.859166</td>\n",
       "      <td>0.508669</td>\n",
       "      <td>0.572793</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:18:25,530] Trial 3 finished with value: 0.5086687909388709 and parameters: {'learning_rate': 2.1328197658376225e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.02889862350110859}. Best is trial 1 with value: 0.5533859440836184.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>0.859327</td>\n",
       "      <td>0.564796</td>\n",
       "      <td>0.572845</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.795800</td>\n",
       "      <td>0.840219</td>\n",
       "      <td>0.541639</td>\n",
       "      <td>0.553598</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:19:57,875] Trial 4 finished with value: 0.5416385235357789 and parameters: {'learning_rate': 3.192941551111017e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.02027946421032999}. Best is trial 1 with value: 0.5533859440836184.\n"
     ]
    }
   ],
   "source": [
    "best_run_bertweet = trainer_bertweet.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=5,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    hp_space=lambda trial: {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6wgbDT3amJi"
   },
   "source": [
    "#### Best BertTweet params training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "RjfkSdReaoxU",
    "outputId": "864fd3f5-0760-4bf3-89f6-93399a6ec287"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>0.585329</td>\n",
       "      <td>0.588749</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>0.840228</td>\n",
       "      <td>0.553386</td>\n",
       "      <td>0.565454</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./bertweet-finetuned-best/tokenizer_config.json',\n",
       " './bertweet-finetuned-best/special_tokens_map.json',\n",
       " './bertweet-finetuned-best/vocab.txt',\n",
       " './bertweet-finetuned-best/bpe.codes',\n",
       " './bertweet-finetuned-best/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparams\n",
    "best_training_args = TrainingArguments(\n",
    "    output_dir=\"./bertweet-finetuned-best\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    **best_run_bertweet.hyperparameters\n",
    ")\n",
    "\n",
    "# Trainer with best found hyperparameters\n",
    "best_trainer_bertweet = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=best_training_args,\n",
    "    train_dataset=tokenized_train_bertweet,\n",
    "    eval_dataset=tokenized_val_bertweet,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_trainer_bertweet.train()\n",
    "best_trainer_bertweet.save_model(\"./bertweet-finetuned-best\")\n",
    "tokenizer_bertweet.save_pretrained(\"./bertweet-finetuned-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5QXQ3xNeDj7"
   },
   "source": [
    "#### BERTweet Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "referenced_widgets": [
      "f27441b128a74c708b71c31addd28558",
      "b54da161650e4219b5f949c58f44c17a",
      "a1046d611635496d8dbf05621115acbd",
      "9f08fce033354e26a4ed84c63abec560",
      "47b4b9445e0641cea9ba9acd21f1d3ee",
      "58ba29e204ba43ddb7789108bc080cd9",
      "257d210029b449249a16439775104518",
      "8b9d5c0ca5a74aa1a0876202c969be8d",
      "da7c3c5525314275ad429e0f3473efb1",
      "dc1547b69d1447ee9540b83a83976ea8",
      "5c21f883bfbb45bea370b7404a47a853"
     ]
    },
    "id": "DwOLtLypd4sB",
    "outputId": "9e075891-8947-44fd-a74f-e7d60b2ec185"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27441b128a74c708b71c31addd28558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/158 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_bertweet = get_tokenized_dataset_bertweet(filtered_test_dataset, tokenizer_bertweet)\n",
    "bertweet_results = best_trainer_bertweet.evaluate(eval_dataset=tokenized_test_bertweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGo3ysMBM0Sv"
   },
   "source": [
    "### 4.3 XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "a6f7e55b6cf744bc886e23d7e23a0199",
      "b8c27a4ba46045f18378d5619c11335c",
      "4f0af837af2a408593019f7bdcee9518",
      "a1fd59956a984d69aa2b6938e80c10d5",
      "65efc5207828492e871fc45672efc6db",
      "a3851047eee843f5ac4e61112de905e7",
      "28b0d1856000429aa23153fe68d5d6de",
      "e170695fab83487dabb90fb32872bd2d",
      "06073ecef3e34f4a8698e49c1ab7640b",
      "374dc4c40e2a4103bb823ea8378f2f42",
      "4ac2af3c50d14935b045de3b50dcc644",
      "b5d30b7d6a644d9db5c72d2193ea4ffd",
      "a43d34b1c796422984d24ba8eaf825e2",
      "1a7a768b41884d8cb396b8c296e2b889",
      "86766f3ecf634c02977cb2fe2fc08e5f",
      "2a96bf52e85c4fc392a93c87b16c5778",
      "b726025f281149e7aafc89d009a21433",
      "12d02c7ea2ea4b24ad7ace464825de55",
      "7ffc79e020a5432ea75f5e864ab36fe0",
      "cf3dedf97ea94cbd8004bad06f8f1f46",
      "0928b8fdd3f64f678860af5a10269afb",
      "9ac09af3149a471ea2ec629a93e0f32d"
     ]
    },
    "id": "veYjXkWnfBGO",
    "outputId": "cb512c47-f4c7-4d23-a9c1-3b4e09430962"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f7e55b6cf744bc886e23d7e23a0199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d30b7d6a644d9db5c72d2193ea4ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "\n",
    "# Load tokenizer and XLMRoberta\n",
    "tokenizer_xlm = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset with XLM tokenizer\n",
    "tokenized_train_xlm = get_tokenized_dataset(filtered_train_dataset, tokenizer_xlm)\n",
    "tokenized_val_xlm= get_tokenized_dataset(filtered_val_dataset, tokenizer_xlm)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./xlm-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_xlm = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_xlm,\n",
    "    eval_dataset=tokenized_val_xlm,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kT7jWLuofa7w"
   },
   "source": [
    "#### XLM HyperParam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aqsB8mZEfcgQ",
    "outputId": "2ba6178f-aee7-475a-afb7-94030618b387"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:22:12,944] A new study created in memory with name: no-name-857587b2-80a0-4157-9b9d-68af4ff14c40\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 02:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.032200</td>\n",
       "      <td>0.940465</td>\n",
       "      <td>0.457721</td>\n",
       "      <td>0.450555</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.511450</td>\n",
       "      <td>0.858974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.964700</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>0.524389</td>\n",
       "      <td>0.571294</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:25:01,758] Trial 0 finished with value: 0.5243891910558578 and parameters: {'learning_rate': 4.344725731696079e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.03585979083818246}. Best is trial 0 with value: 0.5243891910558578.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 02:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.031300</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.550896</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.903990</td>\n",
       "      <td>0.555627</td>\n",
       "      <td>0.559182</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 05:27:33,712] Trial 1 finished with value: 0.5556268064978866 and parameters: {'learning_rate': 3.8203756491715976e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.037520527781157845}. Best is trial 1 with value: 0.5556268064978866.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [477/477 04:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.054500</td>\n",
       "      <td>1.038305</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.043000</td>\n",
       "      <td>1.036654</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>1.030514</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:31:53,873] Trial 2 finished with value: 0.312962962962963 and parameters: {'learning_rate': 4.841040987247629e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.06392137841756072}. Best is trial 1 with value: 0.5556268064978866.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 03:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.033800</td>\n",
       "      <td>0.985783</td>\n",
       "      <td>0.311547</td>\n",
       "      <td>0.231713</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.947100</td>\n",
       "      <td>0.909743</td>\n",
       "      <td>0.447804</td>\n",
       "      <td>0.413047</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.896510</td>\n",
       "      <td>0.546611</td>\n",
       "      <td>0.560142</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.617886</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:35:49,116] Trial 3 finished with value: 0.5466112162838831 and parameters: {'learning_rate': 2.7438890107452094e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.08027773417754858}. Best is trial 1 with value: 0.5556268064978866.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [477/477 04:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.043700</td>\n",
       "      <td>0.960926</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>1.030549</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.984700</td>\n",
       "      <td>1.020519</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>0.566598</td>\n",
       "      <td>0.487654</td>\n",
       "      <td>0.487654</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-04-15 05:40:12,062] Trial 4 finished with value: 0.3263936435484553 and parameters: {'learning_rate': 4.071545059365004e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.0450502372749845}. Best is trial 1 with value: 0.5556268064978866.\n"
     ]
    }
   ],
   "source": [
    "best_run_xlm = trainer_xlm.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=5,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    hp_space=lambda trial: {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nBhMVnJfi98"
   },
   "source": [
    "#### XLM Best HyperParam Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "H5SbrHcufksg",
    "outputId": "707fdf19-c93a-450f-9e3d-739b433279cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 02:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Normal F1</th>\n",
       "      <th>Normal Precision</th>\n",
       "      <th>Normal Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Hatespeech F1</th>\n",
       "      <th>Hatespeech Precision</th>\n",
       "      <th>Hatespeech Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.031300</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.550896</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.903990</td>\n",
       "      <td>0.555627</td>\n",
       "      <td>0.559182</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./xlm-finetuned-best/tokenizer_config.json',\n",
       " './xlm-finetuned-best/special_tokens_map.json',\n",
       " './xlm-finetuned-best/sentencepiece.bpe.model',\n",
       " './xlm-finetuned-best/added_tokens.json',\n",
       " './xlm-finetuned-best/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparams\n",
    "best_training_args = TrainingArguments(\n",
    "    output_dir=\"./xlm-finetuned-best\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    **best_run_xlm.hyperparameters\n",
    ")\n",
    "\n",
    "# Trainer with best found hyperparameters\n",
    "best_trainer_xlm = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=best_training_args,\n",
    "    train_dataset=tokenized_train_xlm,\n",
    "    eval_dataset=tokenized_val_xlm,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_trainer_xlm.train()\n",
    "best_trainer_xlm.save_model(\"./xlm-finetuned-best\")\n",
    "tokenizer_xlm.save_pretrained(\"./xlm-finetuned-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZ3ev1HlfvO2"
   },
   "source": [
    "#### XLM Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "referenced_widgets": [
      "31023a5d85984377bf5c93beb091535c",
      "4e64dd9aa7534357a6901ca670561b9f",
      "dc05b6f761144446a560a4b8c1765807",
      "8a8f528c6b224e9482889247d0822ca1",
      "4d80c5326144452d89672f7d05ad6292",
      "0b5faff971ae4f2682bbf63eb612d0a8",
      "8a973b6bcfff42a09ba97511f3576d44",
      "3ed2152767f64c88816b1ae992ce7d0e",
      "090ddc404a22460d8eac48345a9d2e85",
      "ac9b3832cfa34fea9ae9408eae424a64",
      "4b330add8c594dcf952b0ffccac17c26"
     ]
    },
    "id": "x1rBE6zFfwM1",
    "outputId": "e8cbccb3-7183-4f52-db30-fc71cd0dcadd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31023a5d85984377bf5c93beb091535c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/158 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_xlm = get_tokenized_dataset(filtered_test_dataset, tokenizer_xlm)\n",
    "xlm_results = best_trainer_xlm.evaluate(eval_dataset=tokenized_test_xlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_1WRlN0x0Rp"
   },
   "source": [
    "## 5. Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8kCtjL3Md0c"
   },
   "source": [
    "### Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "fyr11c-jOjiW",
    "outputId": "78536630-fb84-4994-c6c7-ffbbb3079112"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"pretty_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Zero-Shot RoBERTa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.165823611488218,\n        \"min\": 0.0,\n        \"max\": 78.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.25792561056856406,\n          0.3037974683544304,\n          0.47368421052631576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Most Frequent Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.15730187749205,\n        \"min\": 0.0,\n        \"max\": 78.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.243710943759013,\n          54.0,\n          0.6610169491525424\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "pretty_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-34f52a64-d8db-4be3-a23b-bf7a8f99eb47\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>Zero-Shot RoBERTa</th>\n",
       "      <th>Most Frequent Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal_precision</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_recall</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_f1-score</th>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_support</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_f1-score</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_support</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_precision</th>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_recall</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_f1-score</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.661017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_support</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <td>0.257926</td>\n",
       "      <td>0.243711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <td>0.267375</td>\n",
       "      <td>0.326325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34f52a64-d8db-4be3-a23b-bf7a8f99eb47')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-34f52a64-d8db-4be3-a23b-bf7a8f99eb47 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-34f52a64-d8db-4be3-a23b-bf7a8f99eb47');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-57f22190-52fc-43f6-9211-62c3792005dc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57f22190-52fc-43f6-9211-62c3792005dc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-57f22190-52fc-43f6-9211-62c3792005dc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_9acc2d43-d14d-4eb8-88a8-c3a9db9ff486\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pretty_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9acc2d43-d14d-4eb8-88a8-c3a9db9ff486 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pretty_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "model                   Zero-Shot RoBERTa  Most Frequent Class\n",
       "normal_precision                 0.473684             0.000000\n",
       "normal_recall                    0.461538             0.000000\n",
       "normal_f1-score                  0.467532             0.000000\n",
       "normal_support                  78.000000            54.000000\n",
       "offensive_precision              0.000000             0.000000\n",
       "offensive_recall                 0.000000             0.000000\n",
       "offensive_f1-score               0.000000             0.000000\n",
       "offensive_support               54.000000            26.000000\n",
       "hatespeech_precision             0.146341             0.493671\n",
       "hatespeech_recall                0.461538             1.000000\n",
       "hatespeech_f1-score              0.222222             0.661017\n",
       "hatespeech_support              26.000000            78.000000\n",
       "accuracy                         0.303797             0.493671\n",
       "weighted avg_precision           0.257926             0.243711\n",
       "weighted avg_recall              0.303797             0.493671\n",
       "weighted avg_f1-score            0.267375             0.326325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to flatten a classification report\n",
    "def flatten_report(report_dict, model_name):\n",
    "    flat = {}\n",
    "    for label, metrics in report_dict.items():\n",
    "        if isinstance(metrics, dict):  # skip 'accuracy' as a float\n",
    "            for metric, value in metrics.items():\n",
    "                flat[f\"{label}_{metric}\"] = value\n",
    "        else:\n",
    "            flat[f\"{label}\"] = metrics  # e.g. accuracy\n",
    "    flat[\"model\"] = model_name\n",
    "    return flat\n",
    "\n",
    "# Flatten both reports\n",
    "roberta_flat = flatten_report(zero_shot_roberta_results, \"Zero-Shot RoBERTa\")\n",
    "naive_flat = flatten_report(most_freq_class_classifier_results, \"Most Frequent Class\")\n",
    "\n",
    "# Create a DataFrame\n",
    "flat_df = pd.DataFrame([roberta_flat, naive_flat])\n",
    "\n",
    "# Set model as index and transpose\n",
    "flat_df.set_index(\"model\", inplace=True)\n",
    "#display(flat_df)\n",
    "flat_df.drop(columns=[\"macro avg_precision\", \"macro avg_recall\", \"macro avg_support\", \"macro avg_f1-score\", \"weighted avg_support\"], inplace=True)\n",
    "\n",
    "pretty_df = flat_df.T\n",
    "display(pretty_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tecpe9FcMg-y"
   },
   "source": [
    "### Fine-Tuned Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMyLCUeU_kDv"
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "model_names = [\"RoBERTa\", \"HateBERT\", \"BERTweet\", \"XLM-RoBERTa\"]\n",
    "for name, results in zip(model_names, [roberta_results, hatebert_results, bertweet_results, xlm_results]):\n",
    "    results[\"model\"] = name\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "yFBa1uy9_v0D",
    "outputId": "c96589d8-fd81-469b-d15f-9e4b2ecd442b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"RoBERTa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12767920487915546,\n        \"min\": 0.34615384615384615,\n        \"max\": 0.8535271883010864,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.55,\n          0.8535271883010864,\n          0.4782608695652174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HateBERT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10316672680407613,\n        \"min\": 0.5,\n        \"max\": 0.8827701807022095,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.5789473684210527,\n          0.6358381502890174,\n          0.8827701807022095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BERTweet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11554232189525228,\n        \"min\": 0.41379310344827586,\n        \"max\": 0.8606504797935486,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.5714285714285714,\n          0.46153846153846156,\n          0.8606504797935486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XLM-RoBERTa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1731594905523357,\n        \"min\": 0.23076923076923078,\n        \"max\": 0.9242138266563416,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.5070422535211268,\n          0.23076923076923078,\n          0.9242138266563416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-23152af4-29d4-4c30-8a8e-ab544609defe\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>HateBERT</th>\n",
       "      <th>BERTweet</th>\n",
       "      <th>XLM-RoBERTa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_loss</th>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.882770</td>\n",
       "      <td>0.860650</td>\n",
       "      <td>0.924214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1</th>\n",
       "      <td>0.472488</td>\n",
       "      <td>0.598392</td>\n",
       "      <td>0.576210</td>\n",
       "      <td>0.484849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_precision</th>\n",
       "      <td>0.481040</td>\n",
       "      <td>0.614217</td>\n",
       "      <td>0.593028</td>\n",
       "      <td>0.483318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_recall</th>\n",
       "      <td>0.474684</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.474684</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_f1</th>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.595041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_precision</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_recall</th>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_f1</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_precision</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive_recall</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_f1</th>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.483221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_precision</th>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.507042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech_recall</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23152af4-29d4-4c30-8a8e-ab544609defe')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-23152af4-29d4-4c30-8a8e-ab544609defe button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-23152af4-29d4-4c30-8a8e-ab544609defe');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-185befc8-121d-4f60-8210-b6829c85c032\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-185befc8-121d-4f60-8210-b6829c85c032')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-185befc8-121d-4f60-8210-b6829c85c032 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "model                  RoBERTa  HateBERT  BERTweet  XLM-RoBERTa\n",
       "overall_loss          0.853527  0.882770  0.860650     0.924214\n",
       "overall_f1            0.472488  0.598392  0.576210     0.484849\n",
       "overall_precision     0.481040  0.614217  0.593028     0.483318\n",
       "overall_recall        0.474684  0.601266  0.575949     0.493671\n",
       "overall_accuracy      0.474684  0.601266  0.575949     0.493671\n",
       "normal_f1             0.468085  0.586957  0.586957     0.595041\n",
       "normal_precision      0.550000  0.710526  0.710526     0.537313\n",
       "normal_recall         0.407407  0.500000  0.500000     0.666667\n",
       "offensive_f1          0.346154  0.509804  0.436364     0.260870\n",
       "offensive_precision   0.346154  0.520000  0.413793     0.300000\n",
       "offensive_recall      0.346154  0.500000  0.461538     0.230769\n",
       "hatespeech_f1         0.517647  0.635838  0.615385     0.483221\n",
       "hatespeech_precision  0.478261  0.578947  0.571429     0.507042\n",
       "hatespeech_recall     0.564103  0.705128  0.666667     0.461538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.drop(columns=[\"eval_runtime\", \"eval_samples_per_second\", \"eval_steps_per_second\", \"eval_model_preparation_time\", \"epoch\"], inplace=True)\n",
    "results_df.rename(columns={\"eval_loss\": \"overall_loss\", \"eval_f1\": \"overall_f1\", \"eval_precision\": \"overall_precision\", \"eval_recall\": \"overall_recall\", \"eval_accuracy\": \"overall_accuracy\"}, inplace=True)\n",
    "results_df.rename(columns={\"eval_normal_f1\": \"normal_f1\", \"eval_normal_precision\": \"normal_precision\", \"eval_normal_recall\": \"normal_recall\"}, inplace=True)\n",
    "results_df.rename(columns={\"eval_offensive_f1\": \"offensive_f1\", \"eval_offensive_precision\": \"offensive_precision\", \"eval_offensive_recall\": \"offensive_recall\"}, inplace=True)\n",
    "results_df.rename(columns={\"eval_hatespeech_f1\": \"hatespeech_f1\", \"eval_hatespeech_precision\": \"hatespeech_precision\", \"eval_hatespeech_recall\": \"hatespeech_recall\"}, inplace=True)\n",
    "\n",
    "\n",
    "results_df.set_index(\"model\", inplace=True)\n",
    "display(results_df.T)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YIL1eUtV9mTC",
    "wWa-WH_gSW3p",
    "cE4l1UzvU1J_",
    "1vrhCf1viTWu",
    "yys_qygFw7oB",
    "Lco81KinjIyh",
    "ZVpD6vSNR6hS",
    "U8kCtjL3Md0c"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
